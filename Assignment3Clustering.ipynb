{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.display.max_columns = None\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('figure', figsize=[10,5])\n",
    "import mlrose_hiive\n",
    "from sklearn.metrics import f1_score\n",
    "from functools import partial\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.display.max_columns = None\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('figure', figsize=[10,5])\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score, homogeneity_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "np.random.seed(88)\n",
    "bank = pd.read_csv(\"banking_data.csv\")\n",
    "#bank.head()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "bankX = bank.drop(\"Bankrupt\", 1).copy().values\n",
    "bankY = bank[\"Bankrupt\"].copy().values\n",
    "bankX = min_max_scaler.fit_transform(bankX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = list(range(15,45,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sse = {}\n",
    "for cluster in list(range(1,150,1)):\n",
    "    kmeans = KMeans(n_clusters=cluster, max_iter=1000, random_state=44, n_jobs=-2).fit(bankX)\n",
    "    sse[cluster] = kmeans.inertia_\n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Values of K\")\n",
    "plt.ylabel(\"Squared Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, n_init=50, max_iter=1000, random_state=44, n_jobs=-2).fit(bankX)\n",
    "accuracy_score((1-kmeans.labels_), bankY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, n_init=50, max_iter=1000, random_state=44, n_jobs=-2).fit(bankX)\n",
    "adjusted_mutual_info_score((1-kmeans.labels_), bankY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "silh = {}\n",
    "homog = {}\n",
    "for cluster in range(15, 45, 1):\n",
    "    kmeans = KMeans(n_clusters=cluster, n_init=50, max_iter=1000, random_state=44, \n",
    "                    n_jobs=-2).fit(bankX)\n",
    "    label = kmeans.labels_\n",
    "    sil_coeff = silhouette_score(bankX, label, metric='euclidean')\n",
    "    homog_score = homogeneity_score(bankY, label)\n",
    "    silh[cluster] = sil_coeff\n",
    "    homog[cluster] = homog_score\n",
    "    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(cluster, sil_coeff))\n",
    "    print(\"For n_clusters={}, The homogeneity_score is {}\".format(cluster, homog_score))\n",
    "plt.figure()\n",
    "plt.plot(list(silh.keys()), list(silh.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(list(silh.keys()), list(silh.values()), 'r', label=\"Silhouette\")\n",
    "plt.plot(list(homog.keys()), list(homog.values()), 'g', label=\"Homogeneity\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "silh_EM = {}\n",
    "homog_EM = {}\n",
    "log_likelihood_EM = {}\n",
    "for cluster in range(2, 15, 1):\n",
    "    gmm = GaussianMixture(n_components=cluster, max_iter=100, random_state=44, \n",
    "                          n_init=5).fit(bankX)\n",
    "    label = gmm.predict(bankX)\n",
    "    sil_coeff = silhouette_score(bankX, label, metric='euclidean')\n",
    "    homog_score = homogeneity_score(bankY, label)\n",
    "    silh_EM[cluster] = sil_coeff\n",
    "    homog_EM[cluster] = homog_score\n",
    "    log_likelihood_EM[cluster] = gmm.score(bankX)\n",
    "    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(cluster, sil_coeff))\n",
    "    print(\"For n_clusters={}, The homogeneity_score is {}\".format(cluster, homog_score))\n",
    "    print(\"For n_clusters={}, The log_likelihood score is {}\".format(cluster, log_likelihood_EM[cluster]))\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(list(silh_EM.keys()), list(silh_EM.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(list(silh_EM.keys()), list(silh_EM.values()), 'r', label=\"Silhouette\")\n",
    "plt.plot(list(homog_EM.keys()), list(homog_EM.values()), 'g', label=\"Homogeneity\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=2, max_iter=100, random_state=44, \n",
    "                      n_init=5).fit(bankX)\n",
    "label = gmm.predict(bankX)\n",
    "accuracy_score((1-label), bankY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=31, n_init=50, max_iter=1000, random_state=44, \n",
    "                n_jobs=-2).fit(bankX)\n",
    "label = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kmeans = label.reshape(6819,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_kmeans, \n",
    "                                                    bankY, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=88,\n",
    "                                                    stratify=bankY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "def stratFold(train_X_all, train_y_all, classifier, metric, average=None,\n",
    "              fold=5):\n",
    "    train_metric, val_metric, indices = [], [], []\n",
    "    for m in range(100, len(train_X_all), 100):\n",
    "        train_X = train_X_all[:m]\n",
    "        train_y = train_y_all[:m]\n",
    "        skfolds = StratifiedKFold(n_splits=fold)\n",
    "        metric_list = []\n",
    "        metric_list_train = []\n",
    "        for train_index, test_index in skfolds.split(train_X, train_y):\n",
    "            train_X_folds = train_X[train_index, :]\n",
    "            train_y_folds = train_y[train_index]\n",
    "            test_X_fold = train_X[test_index, :]\n",
    "            test_y_fold = train_y[test_index]\n",
    "            classifier.fit(train_X_folds, train_y_folds)\n",
    "            train_y_folds_pred = classifier.predict(train_X_folds)\n",
    "            test_y_fold_pred = classifier.predict(test_X_fold)\n",
    "            if average:\n",
    "                metric_list.append(metric(test_y_fold, test_y_fold_pred,\n",
    "                                     average=average))\n",
    "                metric_list_train.append(metric(train_y_folds, train_y_folds_pred, \n",
    "                                            average=average))\n",
    "            else:\n",
    "                metric_list.append(metric(test_y_fold, test_y_fold_pred))\n",
    "                metric_list_train.append(metric(train_y_folds, train_y_folds_pred))\n",
    "                \n",
    "        test_avg = sum(metric_list)/len(metric_list)\n",
    "        train_avg = sum(metric_list_train)/len(metric_list_train)\n",
    "        val_metric.append(test_avg)\n",
    "        train_metric.append(train_avg)\n",
    "        indices.append(m)\n",
    "    \n",
    "    return train_metric, val_metric, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_complexity(train_scores, val_scores, indices, title, inverse_x=True):\n",
    "    plt.plot(indices, train_scores , \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(indices, val_scores, \"b-+\", linewidth=2, label=\"validation\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    if inverse_x:\n",
    "        plt.gca().invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(train_scores, val_scores, indices, title, inverse_x=False):\n",
    "    plt.plot(indices, train_scores , \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(indices, val_scores, \"b-+\", linewidth=2, label=\"validation\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    if inverse_x:\n",
    "        plt.gca().invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_scores = stratFold(X_train, y_train, neural_net, f1_score, \n",
    "                      average=\"weighted\")\n",
    "plot_learning_curve(f1_scores[0], f1_scores[1], f1_scores[2], \n",
    "                    title=\"f1_weighted score learning curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
    "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=75, learning_rate='constant',\n",
    "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
    "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
    "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
    "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "              warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net.fit(X_kmeans, bankY)\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "bank_train_predictions = best_net.predict(X_kmeans)\n",
    "accuracy = accuracy_score(bankY, bank_train_predictions)\n",
    "print(accuracy)\n",
    "print(classification_report(bankY, bank_train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "best_net.fit(X_train, y_train)\n",
    "test_predictions = best_net.predict(X_test)\n",
    "print(classification_report(y_test, test_predictions, digits=5))\n",
    "print(confusion_matrix(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gmm = GaussianMixture(n_components=31, max_iter=100, random_state=44, \n",
    "                      n_init=5).fit(bankX)\n",
    "label = gmm.predict(bankX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_em = label.reshape(6819,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_net = MLPClassifier()\n",
    "neural_net.fit(X_em, bankY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_em, \n",
    "                                                    bankY, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=88,\n",
    "                                                    stratify=bankY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_scores = stratFold(X_train, y_train, best_net, f1_score, \n",
    "                      average=\"weighted\")\n",
    "plot_learning_curve(f1_scores[0], f1_scores[1], f1_scores[2], \n",
    "                    title=\"f1_weighted score learning curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR = pd.read_csv(\"HR_data.csv\")\n",
    "HR_orig = pd.read_csv(\"HR_data.csv\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)\n",
    "\n",
    "HR['city']=HR['city'].astype(str)\n",
    "HR['gender']=HR['gender'].astype(str)\n",
    "HR['relevent_experience']=HR['relevent_experience'].astype(str)\n",
    "HR['enrolled_university']=HR['enrolled_university'].astype(str)\n",
    "HR['education_level']=HR['education_level'].astype(str)\n",
    "HR['major_discipline']=HR['major_discipline'].astype(str)\n",
    "HR['experience']=HR['experience'].astype(str)\n",
    "HR['company_size']=HR['company_size'].astype(str)\n",
    "HR['company_type']=HR['company_type'].astype(str)\n",
    "HR['last_new_job']=HR['last_new_job'].astype(str)\n",
    "HR = MultiColumnLabelEncoder(columns = ['city','gender','relevent_experience','enrolled_university','education_level','major_discipline','experience','company_size','company_type','last_new_job']).fit_transform(HR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrX = HR.drop(\"target\", 1).copy().values\n",
    "hrY = HR[\"target\"].copy().values\n",
    "hr_x_df = HR.drop(\"target\",1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "hrX = min_max_scaler.fit_transform(hrX)\n",
    "hrX_df = pd.DataFrame(hrX, columns=hr_x_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = list(range(1,150,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sse = {}\n",
    "for cluster in list(range(1,150,1)):\n",
    "    kmeans = KMeans(n_clusters=cluster, max_iter=1000, random_state=44, n_jobs=-2).fit(hrX)\n",
    "    sse[cluster] = kmeans.inertia_\n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Values of K\")\n",
    "plt.ylabel(\"Squared Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "silh = {}\n",
    "homog = {}\n",
    "for cluster in range(3, 20, 1):\n",
    "    kmeans = KMeans(n_clusters=cluster, n_init=50, max_iter=1000, random_state=44, \n",
    "                    n_jobs=-2).fit(hrX)\n",
    "    label = kmeans.labels_\n",
    "    sil_coeff = silhouette_score(hrX, label, metric='euclidean')\n",
    "    homog_score = homogeneity_score(hrY, label)\n",
    "    silh[cluster] = sil_coeff\n",
    "    homog[cluster] = homog_score\n",
    "    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(cluster, sil_coeff))\n",
    "    print(\"For n_clusters={}, The homogeneity_score is {}\".format(cluster, homog_score))\n",
    "plt.figure()\n",
    "plt.plot(list(silh.keys()), list(silh.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(list(silh.keys()), list(silh.values()), 'r', label=\"Silhouette\")\n",
    "plt.plot(list(homog.keys()), list(homog.values()), 'g', label=\"Homogeneity\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, n_init=50, max_iter=1000, random_state=44, n_jobs=-2).fit(hrX)\n",
    "accuracy_score((1-kmeans.labels_), hrY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "silh_EM = {}\n",
    "homog_EM = {}\n",
    "log_likelihood_EM = {}\n",
    "for cluster in range(2, 21, 1):\n",
    "    gmm = GaussianMixture(n_components=cluster, max_iter=100, random_state=44, \n",
    "                          n_init=5).fit(hrX)\n",
    "    label = gmm.predict(hrX)\n",
    "    sil_coeff = silhouette_score(hrX, label, metric='euclidean')\n",
    "    homog_score = homogeneity_score(hrY, label)\n",
    "    silh_EM[cluster] = sil_coeff\n",
    "    homog_EM[cluster] = homog_score\n",
    "    log_likelihood_EM[cluster] = gmm.score(hrX)\n",
    "    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(cluster, sil_coeff))\n",
    "    print(\"For n_clusters={}, The homogeneity_score is {}\".format(cluster, homog_score))\n",
    "    print(\"For n_clusters={}, The log_likelihood score is {}\".format(cluster, log_likelihood_EM[cluster]))\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(list(silh_EM.keys()), list(silh_EM.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(list(silh_EM.keys()), list(silh_EM.values()), 'r', label=\"Silhouette\")\n",
    "plt.plot(list(homog_EM.keys()), list(homog_EM.values()), 'g', label=\"Homogeneity\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=2, max_iter=100, random_state=44, \n",
    "                      n_init=5).fit(hrX)\n",
    "label = gmm.predict(hrX)\n",
    "accuracy_score((1-label), hrY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=60, n_init=50, max_iter=1000, random_state=44, \n",
    "                n_jobs=-2).fit(hrX)\n",
    "label = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kmeans = label.reshape(19158,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_kmeans, \n",
    "                                                    hrY, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=hrY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_net = MLPClassifier()\n",
    "neural_net.fit(X_kmeans, hrY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import f1_score\n",
    "f1_scores = stratFold(X_train, y_train, neural_net, f1_score, \n",
    "                      average=\"macro\")\n",
    "plot_learning_curve(f1_scores[0], f1_scores[1], f1_scores[2], \n",
    "                    title=\"f1_weighted score learning curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
